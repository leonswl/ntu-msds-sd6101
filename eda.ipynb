{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## EDA \n",
    "\n",
    "1. Chi-Square Test of Indepedence\n",
    "2. One-way ANOVA test for Variance Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import dependencies\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "listing out all the column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>address</th>\n",
       "      <th>famsize</th>\n",
       "      <th>Pstatus</th>\n",
       "      <th>Medu</th>\n",
       "      <th>Fedu</th>\n",
       "      <th>Mjob</th>\n",
       "      <th>Fjob</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>18</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>A</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>at_home</td>\n",
       "      <td>teacher</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>17</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>LE3</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>at_home</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>15</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>health</td>\n",
       "      <td>services</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>15</td>\n",
       "      <td>14</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GP</td>\n",
       "      <td>F</td>\n",
       "      <td>16</td>\n",
       "      <td>U</td>\n",
       "      <td>GT3</td>\n",
       "      <td>T</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>other</td>\n",
       "      <td>other</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  school sex  age address famsize Pstatus  Medu  Fedu     Mjob      Fjob  ...  \\\n",
       "0     GP   F   18       U     GT3       A     4     4  at_home   teacher  ...   \n",
       "1     GP   F   17       U     GT3       T     1     1  at_home     other  ...   \n",
       "2     GP   F   15       U     LE3       T     1     1  at_home     other  ...   \n",
       "3     GP   F   15       U     GT3       T     4     2   health  services  ...   \n",
       "4     GP   F   16       U     GT3       T     3     3    other     other  ...   \n",
       "\n",
       "  famrel freetime  goout  Dalc  Walc health absences  G1  G2  G3  \n",
       "0      4        3      4     1     1      3        6   5   6   6  \n",
       "1      5        3      3     1     1      3        4   5   5   6  \n",
       "2      4        3      2     2     3      3       10   7   8  10  \n",
       "3      3        2      2     1     1      5        2  15  14  15  \n",
       "4      4        3      2     1     2      5        4   6  10  10  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mat = pd.read_csv(\"artifacts/raw/middle-student-mat.csv\",sep=\";\")\n",
    "data_mat.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to the large number of attributes, we narrowed our scope to focus on features that are uncontrollable by students (i.e. Students inherent background). These features include:\n",
    "\n",
    "- School\n",
    "- Sex\n",
    "- Age\n",
    "- Address\n",
    "- Famsize (Family Size)\n",
    "- Pstatus (Parent's Cohabitation Status)\n",
    "- Medu (Mother's Education)\n",
    "- Fedu (Father's Education)\n",
    "- Mjob (Mother's Job)\n",
    "- Fjob (Father's Job)\n",
    "- Reason (Reason to choose this school)\n",
    "- Nursery (attended nursery school)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['school',\n",
       " 'sex',\n",
       " 'age',\n",
       " 'address',\n",
       " 'famsize',\n",
       " 'Pstatus',\n",
       " 'Medu',\n",
       " 'Fedu',\n",
       " 'Mjob',\n",
       " 'Fjob',\n",
       " 'reason',\n",
       " 'nursery']"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "independent_feat = ['school','sex','age','address','famsize','Pstatus','Medu','Fedu','Mjob', 'Fjob','reason','nursery']\n",
    "independent_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['G3']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dependent_feat = ['G3']\n",
    "dependent_feat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([18, 17, 15, 16, 19, 22, 20, 21])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# unique values for age\n",
    "data_mat['age'].unique()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Testing for correlation between Independent variables\n",
    "\n",
    "Before performing correlation between independent and dependent variables, we will need to test that the independent variables are truly independent of each other.\n",
    "\n",
    "We will use Chi Square test for Independence to verify this for categorical variables. Most of the variables are already categorical data except for `Age`. However, there are only 8 unique values for `Age` hence we will treat `Age` as a categorical variable for the test of independence.\n",
    "\n",
    "- Null Hypothesis: There is **no relationship** between the 2 variables\n",
    "- Alternate Hypothesis: There is **a relationship** betwen the 2 variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.stats as stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_chi_square_results(features, df):\n",
    "    \"\"\"\n",
    "    Calculates chi-square test results for all possible pairs of features in a given data matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        independent_feat (list): List of feature names to compare\n",
    "        data_mat (pandas.DataFrame): Data matrix containing the features\n",
    "    \n",
    "    Returns:\n",
    "        chi_sqr_res_lst (list): List of dictionaries containing chi-square test results for each pair of features\n",
    "    \"\"\"\n",
    "    chi_sqr_res_lst = []  # Initialize an empty list to store the results\n",
    "    \n",
    "    # Loop over all possible pairs of features\n",
    "    for i in range(len(features)):\n",
    "        for j in range(i+1, len(features)):\n",
    "            # Calculate crosstabulation for the two features\n",
    "            crosstab = pd.crosstab(df[features[i]],df[features[j]])\n",
    "            # Perform chi-square test on the crosstabulation\n",
    "            res = stats.chi2_contingency(crosstab)\n",
    "            # Store the results in a dictionary\n",
    "            results_dict = {\n",
    "                'variables': (features[i], features[j]),\n",
    "                'pvalue': res.pvalue,\n",
    "                'statistics': res.statistic,\n",
    "                'dof': res.dof,\n",
    "                'expected_freq': res.expected_freq,\n",
    "            }\n",
    "            # Append the dictionary to the results list\n",
    "            chi_sqr_res_lst.append(results_dict)\n",
    "    \n",
    "    return chi_sqr_res_lst\n",
    "\n",
    "def print_significant_results(chi_sqr_res_lst):\n",
    "    \"\"\"\n",
    "    Prints the variables and p-values for all significant chi-square test results in a list of results.\n",
    "    A result is considered significant if its p-value is less than 0.05.\n",
    "    \n",
    "    Parameters:\n",
    "        chi_sqr_res_lst (list): List of dictionaries containing chi-square test results for each pair of features\n",
    "    \n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    count = 0\n",
    "    data = {}\n",
    "    # Loop over all results in the list\n",
    "    for results in chi_sqr_res_lst:\n",
    "        # Get the p-value and variables for the current result\n",
    "        pvalue = float(results.get('pvalue'))\n",
    "        variables = results.get('variables')\n",
    "        \n",
    "        # Check if the result is significant\n",
    "        if pvalue < 0.05:\n",
    "            # Print the variables and p-value, rounded to 4 decimal places\n",
    "            print(variables, pvalue)\n",
    "            count+=1\n",
    "\n",
    "    if count == 0:\n",
    "        print(\"There are no variables that have relationship with each other\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('school', 'age') 2.8253973276676154e-13\n",
      "('school', 'address') 7.77068354957483e-08\n",
      "('school', 'Medu') 0.00031360912544192357\n",
      "('school', 'reason') 0.005947834009263454\n",
      "('sex', 'Mjob') 0.0015564385627536573\n",
      "('age', 'address') 0.0034680030378527907\n",
      "('address', 'Medu') 0.019257159259757555\n",
      "('address', 'Mjob') 0.01013724484686267\n",
      "('address', 'reason') 0.021804456830089435\n",
      "('famsize', 'Pstatus') 0.00524754575877353\n",
      "('Pstatus', 'Medu') 0.010369983537476098\n",
      "('Medu', 'Fedu') 8.014562451932377e-34\n",
      "('Medu', 'Mjob') 7.752732260542515e-39\n",
      "('Medu', 'Fjob') 4.8280932164911185e-06\n",
      "('Medu', 'nursery') 0.00026084822887275803\n",
      "('Fedu', 'Mjob') 4.206183361043177e-08\n",
      "('Fedu', 'Fjob') 9.007362084326286e-16\n",
      "('Fedu', 'nursery') 0.02068060288889864\n",
      "('Mjob', 'Fjob') 2.533576541234461e-09\n",
      "('Mjob', 'reason') 0.02818547173558085\n"
     ]
    }
   ],
   "source": [
    "chi_sqr_res_lst = calculate_chi_square_results(features=independent_feat, df=data_mat)\n",
    "dict_chisqr = print_significant_results(chi_sqr_res_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's drop school, address, Fedu, Medu, Fjob and Pstatus and check for relationships using chi square again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sex', 'age', 'famsize', 'Fjob', 'reason', 'nursery']"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_categorical_feats = [feat for feat in independent_feat if feat not in ['school', 'address', 'Fedu', 'Medu','Mjob','Pstatus']]\n",
    "new_categorical_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are no variables that have relationship with each other\n"
     ]
    }
   ],
   "source": [
    "new_chi_sqr_res_lst = calculate_chi_square_results(features=new_categorical_feats, df=data_mat)\n",
    "print_significant_results(new_chi_sqr_res_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With Chi Square Test of Independence, we can conclude that without the following features - school, address, Fedu, Medu, Fjob and Pstatus, the remaining features *('sex', 'age', 'famsize', 'Mjob', 'reason', 'nursery')* are independent of each other."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Split Features for T-Test and ANOVA\n",
    "\n",
    "Dependeing of the number of sample groups within each categorical feature, that will determine if we should use ANOVA or t-test. Features with more than 2 sample groups will run ANOVA test, while features with 2 sample groups will be tested with t-test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_features_by_test(df, feat_lst):\n",
    "    \"\"\"\n",
    "    Splits the independent features of a dataset into two lists, one for t-tests and one for ANOVA.\n",
    "\n",
    "    Parameters:\n",
    "    df: a pandas DataFrame containing the dataset\n",
    "    independent_feat: a list of the names of the independent features\n",
    "\n",
    "    Returns:\n",
    "    Two lists of the names of the independent features, one for t-tests and one for ANOVA.\n",
    "    \"\"\"\n",
    "\n",
    "    # Initialize empty lists for the t-tests and ANOVA\n",
    "    ttest_lst = []\n",
    "    anova_lst = []\n",
    "\n",
    "    # Loop through each column in the independent features\n",
    "    for col in feat_lst:\n",
    "\n",
    "        # Check the number of unique values in the column\n",
    "        nuniques = df[col].nunique()\n",
    "\n",
    "        # If there are more than 2 unique values, add the column to the list for ANOVA\n",
    "        if nuniques > 2:\n",
    "            anova_lst.append(col)\n",
    "\n",
    "        # Otherwise, add the column to the list for t-tests\n",
    "        else:\n",
    "            ttest_lst.append(col)\n",
    "\n",
    "    # Return the lists of independent features for t-tests and ANOVA\n",
    "    return ttest_lst, anova_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the categorical independent features \n",
    "# note that we are treating AGE as a categorical feature\n",
    "ttest_lst, anova_lst = split_features_by_test(data_mat, independent_feat)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Testing for Homogeneity of Variance\n",
    "\n",
    "- Null Hypothesis: The distribution, or “spread,” of scores around the mean of two or more samples are **considered equal**.\n",
    "- Alternative Hypothesis: The distribution, or “spread,” of scores around the mean of two or more samples are **not equal**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import levene\n",
    "\n",
    "def calculate_levene_tests(unique_array_lst, feats):\n",
    "    \"\"\"\n",
    "    Calculates the Levene test statistic and p-value for all possible number of sample groups.\n",
    "\n",
    "    Parameters:\n",
    "    unique_array_lst: a list of unique arrays to test. Length of array represents the number of sample groups. Minimum is 2.\n",
    "    feats: the name of the feature being tested\n",
    "\n",
    "    Returns:\n",
    "    A list of dictionaries containing the results of the Levene tests.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Loop through each possible combination of unique arrays\n",
    "    for i in range(2, len(unique_array_lst) + 1):\n",
    "\n",
    "        # Select the first i unique arrays from the list\n",
    "        samples = unique_array_lst[:i]\n",
    "\n",
    "        # Calculate the Levene test statistic and p-value for the selected samples\n",
    "        stat, p = levene(*samples, center='median', proportiontocut=0.05)\n",
    "\n",
    "        # Create a dictionary with the results of the Levene test\n",
    "        levene_dict = {\n",
    "            'feature': feats, # The name of the feature being tested\n",
    "            'statistic': stat, # The calculated Levene test statistic\n",
    "            'pvalue': p # The calculated p-value\n",
    "        }\n",
    "\n",
    "    # Return the list of Levene test results\n",
    "    return levene_dict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sample_groups(df, feat_lst, scores):\n",
    "    \"\"\"\n",
    "    This function returns a list of dictionaries where each dictionary represents a feature in feat_lst\n",
    "    and its corresponding sample groups as arrays. Each dictionary will contain list of arrays, with each array representing the score values for each sample group. \n",
    "    \n",
    "    Args:\n",
    "        df (pandas DataFrame): The data to be used for testing\n",
    "        feat_lst (list): A list of feature names \n",
    "    \n",
    "    Returns:\n",
    "        list: A list of dictionaries representing each feature and its sample groups as arrays.\n",
    "    \"\"\"\n",
    "    sample_groups_array_lst = []\n",
    "    # Loop over each feature in ttest_lst\n",
    "    for feat in feat_lst:\n",
    "        # Get unique values of the current feature\n",
    "        sample_groups = df[feat].unique()\n",
    "        sample_group_array_lst = []\n",
    "        # Loop over each unique value and get the corresponding data points for that value\n",
    "        for i in range(len(sample_groups)):\n",
    "            df_sample_group = df.loc[df[feat] == sample_groups[i]]\n",
    "            # Append the data points as an array to sample_group_array_lst\n",
    "            sample_group_array_lst.append(df_sample_group[scores])\n",
    "        \n",
    "        # Create a dictionary to store the feature name and its corresponding sample groups as arrays\n",
    "        feature_array_dict = {\n",
    "            'feature': feat,\n",
    "            'sample_group_array_lst': sample_group_array_lst\n",
    "        }\n",
    "        # Append the dictionary to sample_groups_array_lst\n",
    "        sample_groups_array_lst.append(feature_array_dict)\n",
    "    \n",
    "    return sample_groups_array_lst\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Testing for Homogeneity of Variance for t-test features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'school',\n",
       "  'statistic': 0.8377081603117896,\n",
       "  'pvalue': 0.3606142973401584},\n",
       " {'feature': 'sex',\n",
       "  'statistic': 0.06847571965446789,\n",
       "  'pvalue': 0.7937062862303847},\n",
       " {'feature': 'address',\n",
       "  'statistic': 0.039462285189423164,\n",
       "  'pvalue': 0.8426383524673037},\n",
       " {'feature': 'famsize',\n",
       "  'statistic': 1.062426470207238,\n",
       "  'pvalue': 0.3032963295247042},\n",
       " {'feature': 'Pstatus',\n",
       "  'statistic': 0.483787387888353,\n",
       "  'pvalue': 0.48712285383963405},\n",
       " {'feature': 'nursery',\n",
       "  'statistic': 0.22789022933888387,\n",
       "  'pvalue': 0.6333579961143636}]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving arrays of sample groups from features that will be tested using t-test \n",
    "ttest_sample_groups_array_lst = get_sample_groups(data_mat, ttest_lst, 'G3')\n",
    "\n",
    "# run levene tests to determine if homogeneity of variance is satisfied\n",
    "ttest_levene_res_lst = []\n",
    "for item in ttest_sample_groups_array_lst:\n",
    "    feat = item.get('feature')\n",
    "    array_lst = item.get('sample_group_array_lst')\n",
    "\n",
    "    levene_dict = calculate_levene_tests(array_lst, feat)\n",
    "    ttest_levene_res_lst.append(levene_dict)\n",
    "\n",
    "ttest_levene_res_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school: welch's t-test\n",
      "sex: welch's t-test\n",
      "address: welch's t-test\n",
      "famsize: welch's t-test\n",
      "Pstatus: welch's t-test\n",
      "nursery: welch's t-test\n"
     ]
    }
   ],
   "source": [
    "for item in ttest_levene_res_lst:\n",
    "    if item.get('pvalue') < 0.05:\n",
    "        print(f\"{item.get('feature')}: student t-test\")\n",
    "    else:\n",
    "        print(f\"{item.get('feature')}: welch's t-test\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all of the features for t-test here fail to meet the assumption of homogeneity of variance. We will go with Welch's t-test instead"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Testing for Homogeneity of Variance for ANOVA features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'age',\n",
       "  'statistic': 0.6184299930183529,\n",
       "  'pvalue': 0.7407570882158565},\n",
       " {'feature': 'Medu',\n",
       "  'statistic': 0.27005190957066255,\n",
       "  'pvalue': 0.8971999681625331},\n",
       " {'feature': 'Fedu',\n",
       "  'statistic': 0.2928719056858835,\n",
       "  'pvalue': 0.8825683002555373},\n",
       " {'feature': 'Mjob',\n",
       "  'statistic': 0.18960947683040633,\n",
       "  'pvalue': 0.9437753301264346},\n",
       " {'feature': 'Fjob',\n",
       "  'statistic': 0.938846216099165,\n",
       "  'pvalue': 0.44132948635335056},\n",
       " {'feature': 'reason',\n",
       "  'statistic': 0.8430266176142672,\n",
       "  'pvalue': 0.4709416983605361}]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# retrieving arrays of sample groups from features that will be tested using t-test \n",
    "anova_sample_groups_array_lst = get_sample_groups(data_mat, anova_lst, 'G3')\n",
    "\n",
    "# run levene tests to determine if homogeneity of variance is satisfied\n",
    "anova_levene_res_lst = []\n",
    "for item in anova_sample_groups_array_lst:\n",
    "    feat = item.get('feature')\n",
    "    array_lst = item.get('sample_group_array_lst')\n",
    "\n",
    "    levene_dict = calculate_levene_tests(array_lst, feat)\n",
    "    anova_levene_res_lst.append(levene_dict)\n",
    "\n",
    "anova_levene_res_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age: Kruskal-Wallis ANOVA\n",
      "Medu: Kruskal-Wallis ANOVA\n",
      "Fedu: Kruskal-Wallis ANOVA\n",
      "Mjob: Kruskal-Wallis ANOVA\n",
      "Fjob: Kruskal-Wallis ANOVA\n",
      "reason: Kruskal-Wallis ANOVA\n"
     ]
    }
   ],
   "source": [
    "for item in anova_levene_res_lst:\n",
    "    if item.get('pvalue') < 0.05:\n",
    "        print(f\"{item.get('feature')}: One-way ANOVA\")\n",
    "    else:\n",
    "        print(f\"{item.get('feature')}: Kruskal-Wallis ANOVA\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that all of the features for ANOVA here fail to meet the assumption of homogeneity of variance. We will go with Kruskal-Wallis ANOVA instead"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Welch's T-test between Independent and Dependent Variable\n",
    "\n",
    "We will use Welch's t-test to compare the grade means against student's background. Only background features with 2 sample groups can be used to run the t-test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def run_ttest(array_lst, feat):\n",
    "    \"\"\"\n",
    "    Perform a t-test on two arrays and return the statistic and p-value.\n",
    "\n",
    "    Args:\n",
    "        array_lst (list): A list containing two arrays to compare.\n",
    "        feat (str): The feature name.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing the feature name, t-test statistic, and p-value.\n",
    "    \"\"\"\n",
    "    stats, p = ttest_ind(array_lst[0], array_lst[1], equal_var = False)\n",
    "    return {'feature': feat, 'statistic': stats, 'pvalue': p}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'feature': 'school',\n",
       "  'statistic': 0.9555475253722291,\n",
       "  'pvalue': 0.3431316933314036},\n",
       " {'feature': 'sex',\n",
       "  'statistic': -2.0650572003629564,\n",
       "  'pvalue': 0.03957700303089973},\n",
       " {'feature': 'address',\n",
       "  'statistic': 2.1101367617785494,\n",
       "  'pvalue': 0.03661381145664286},\n",
       " {'feature': 'famsize',\n",
       "  'statistic': -1.6942894182883583,\n",
       "  'pvalue': 0.09155470562414127},\n",
       " {'feature': 'Pstatus',\n",
       "  'statistic': 1.2196750248412154,\n",
       "  'pvalue': 0.228164691976038},\n",
       " {'feature': 'nursery',\n",
       "  'statistic': 1.0271053558051693,\n",
       "  'pvalue': 0.30635403814971324}]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ttest_res_lst = []\n",
    "for item in ttest_sample_groups_array_lst:\n",
    "    feat = item.get('feature')\n",
    "    array_lst = item.get('sample_group_array_lst')\n",
    "\n",
    "    ttest_dic = run_ttest(array_lst, feat)\n",
    "    ttest_res_lst.append(ttest_dic)\n",
    "ttest_res_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "school: Unable to reject null hypothesis; There are no differences in means\n",
      "sex: Reject null hypothesis; There are significant differences in means\n",
      "address: Reject null hypothesis; There are significant differences in means\n",
      "famsize: Unable to reject null hypothesis; There are no differences in means\n",
      "Pstatus: Unable to reject null hypothesis; There are no differences in means\n",
      "nursery: Unable to reject null hypothesis; There are no differences in means\n"
     ]
    }
   ],
   "source": [
    "for item in ttest_res_lst:\n",
    "    if item.get('pvalue') < 0.05:\n",
    "        print(f\"{item.get('feature')}: Reject null hypothesis; There are significant differences in means\")\n",
    "    else:\n",
    "        print(f\"{item.get('feature')}: Unable to reject null hypothesis; There are no differences in means\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. ANOVA Test between Independent and Dependent Variable\n",
    "\n",
    "We will use a Kruskal-Wallis one-way  ANOVA for comparing variance across the average final grades (G3) against student's background. All background features will be used to check for differences.\n",
    "\n",
    "- Null Hypothesis: There is no difference in means of grades (G3)\n",
    "- Alternate Hypothesis: There is a difference in means of grades (G3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import f_oneway\n",
    "\n",
    "def calculate_anova_results(feats, df):\n",
    "    \"\"\"\n",
    "    Calculates ANOVA test results for each categorical feature in a given data matrix.\n",
    "    \n",
    "    Parameters:\n",
    "        new_categorical_feats (list): List of categorical feature names\n",
    "        data_mat (pandas.DataFrame): Data matrix containing the categorical features\n",
    "    \n",
    "    Returns:\n",
    "        anova_res_lst (list): List of dictionaries containing ANOVA test results for each feature\n",
    "    \"\"\"\n",
    "    anova_res_lst = []  # Initialize an empty list to store the results\n",
    "    \n",
    "    # Loop over all categorical features\n",
    "    for feat in feats:\n",
    "        # Extract the feature and the dependent variable (G3) from the data matrix\n",
    "        df_feats = df[[feat,'G3']]\n",
    "        # Get the unique categories for the feature\n",
    "        categories = df_feats[feat].unique()\n",
    "        # Create a list of dataframes, one for each category\n",
    "        feats_lst = [df_feats.loc[df_feats[feat]== cat] for cat in categories]\n",
    "        print(feats_lst)\n",
    "        # Perform ANOVA test on the dataframes\n",
    "        res = f_oneway(feats_lst[0]['G3'],feats_lst[1]['G3'])\n",
    "        # Store the results in a dictionary\n",
    "        anova_dict = {\n",
    "            'variable': feat,\n",
    "            'statistic': res.statistic,\n",
    "            'pvalue': res.pvalue\n",
    "        }\n",
    "        # Append the dictionary to the results list\n",
    "        anova_res_lst.append(anova_dict)\n",
    "    \n",
    "    return anova_res_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[     age  G3\n",
      "0     18   6\n",
      "128   18   0\n",
      "150   18   0\n",
      "157   18  10\n",
      "213   18   8\n",
      "..   ...  ..\n",
      "385   18  10\n",
      "386   18   6\n",
      "388   18   8\n",
      "389   18   0\n",
      "393   18  10\n",
      "\n",
      "[82 rows x 2 columns],      age  G3\n",
      "1     17   6\n",
      "7     17   6\n",
      "18    17   5\n",
      "78    17  10\n",
      "118   17   8\n",
      "..   ...  ..\n",
      "372   17  11\n",
      "373   17   5\n",
      "379   17  10\n",
      "382   17  10\n",
      "391   17  16\n",
      "\n",
      "[98 rows x 2 columns],      age  G3\n",
      "2     15  10\n",
      "3     15  15\n",
      "8     15  19\n",
      "9     15  15\n",
      "10    15   9\n",
      "..   ...  ..\n",
      "147   15  11\n",
      "149   15  10\n",
      "152   15  10\n",
      "155   15   8\n",
      "161   15   7\n",
      "\n",
      "[82 rows x 2 columns],      age  G3\n",
      "4     16  10\n",
      "5     16  15\n",
      "6     16  11\n",
      "15    16  14\n",
      "16    16  14\n",
      "..   ...  ..\n",
      "243   16  12\n",
      "245   16  18\n",
      "249   16  15\n",
      "251   16  10\n",
      "253   16   8\n",
      "\n",
      "[104 rows x 2 columns],      age  G3\n",
      "127   19   9\n",
      "153   19   0\n",
      "210   19   8\n",
      "257   19  11\n",
      "270   19   9\n",
      "296   19   0\n",
      "304   19  13\n",
      "307   19   8\n",
      "308   19  12\n",
      "309   19  10\n",
      "310   19   0\n",
      "311   19  13\n",
      "312   19  11\n",
      "313   19  11\n",
      "314   19  13\n",
      "315   19  11\n",
      "336   19  13\n",
      "340   19  11\n",
      "350   19   8\n",
      "353   19   8\n",
      "370   19   9\n",
      "383   19   0\n",
      "387   19   0\n",
      "394   19   9,      age  G3\n",
      "247   22   8,      age  G3\n",
      "306   20  18\n",
      "376   20  15\n",
      "390   20   9,      age  G3\n",
      "392   21   7]\n",
      "[     Medu  G3\n",
      "0       4   6\n",
      "3       4  15\n",
      "5       4  15\n",
      "7       4   6\n",
      "10      4   9\n",
      "..    ...  ..\n",
      "376     4  15\n",
      "377     4  10\n",
      "380     4  14\n",
      "384     4   5\n",
      "386     4   6\n",
      "\n",
      "[131 rows x 2 columns],      Medu  G3\n",
      "1       1   6\n",
      "2       1  10\n",
      "58      1   9\n",
      "61      1  11\n",
      "62      1   9\n",
      "72      1   5\n",
      "84      1  10\n",
      "95      1  10\n",
      "118     1   8\n",
      "120     1  15\n",
      "131     1   0\n",
      "138     1  12\n",
      "143     1  13\n",
      "145     1  11\n",
      "147     1  11\n",
      "150     1   0\n",
      "156     1  13\n",
      "157     1  10\n",
      "162     1   0\n",
      "163     1  10\n",
      "164     1   7\n",
      "171     1  16\n",
      "173     1   0\n",
      "186     1  11\n",
      "189     1  10\n",
      "191     1   9\n",
      "192     1   8\n",
      "202     1  10\n",
      "208     1  10\n",
      "221     1   0\n",
      "234     1   6\n",
      "255     1   8\n",
      "272     1  11\n",
      "273     1  14\n",
      "282     1  12\n",
      "283     1  10\n",
      "285     1  11\n",
      "287     1  12\n",
      "309     1  10\n",
      "310     1   0\n",
      "312     1  11\n",
      "314     1  13\n",
      "350     1   8\n",
      "352     1   8\n",
      "353     1   8\n",
      "358     1  10\n",
      "359     1  16\n",
      "360     1  13\n",
      "361     1  12\n",
      "364     1  12\n",
      "365     1  10\n",
      "367     1   0\n",
      "371     1  12\n",
      "373     1   5\n",
      "375     1  10\n",
      "383     1   0\n",
      "389     1   0\n",
      "392     1   7\n",
      "394     1   9,      Medu  G3\n",
      "4       3  10\n",
      "8       3  19\n",
      "9       3  15\n",
      "17      3  10\n",
      "18      3   5\n",
      "..    ...  ..\n",
      "378     3  15\n",
      "379     3  10\n",
      "388     3   8\n",
      "391     3  16\n",
      "393     3  10\n",
      "\n",
      "[99 rows x 2 columns],      Medu  G3\n",
      "6       2  11\n",
      "11      2  12\n",
      "14      2  16\n",
      "23      2  12\n",
      "24      2   8\n",
      "..    ...  ..\n",
      "381     2   7\n",
      "382     2  10\n",
      "385     2  10\n",
      "387     2   0\n",
      "390     2   9\n",
      "\n",
      "[103 rows x 2 columns],      Medu  G3\n",
      "127     0   9\n",
      "249     0  15\n",
      "324     0  15]\n",
      "[     Fedu  G3\n",
      "0       4   6\n",
      "7       4   6\n",
      "9       4  15\n",
      "10      4   9\n",
      "12      4  14\n",
      "..    ...  ..\n",
      "369     4  11\n",
      "374     4  19\n",
      "377     4  10\n",
      "380     4  14\n",
      "386     4   6\n",
      "\n",
      "[96 rows x 2 columns],      Fedu  G3\n",
      "1       1   6\n",
      "2       1  10\n",
      "11      1  12\n",
      "55      1  10\n",
      "61      1  11\n",
      "..    ...  ..\n",
      "388     1   8\n",
      "389     1   0\n",
      "391     1  16\n",
      "392     1   7\n",
      "394     1   9\n",
      "\n",
      "[82 rows x 2 columns],      Fedu  G3\n",
      "3       2  15\n",
      "6       2  11\n",
      "8       2  19\n",
      "14      2  16\n",
      "18      2   5\n",
      "..    ...  ..\n",
      "376     2  15\n",
      "384     2   5\n",
      "385     2  10\n",
      "390     2   9\n",
      "393     2  10\n",
      "\n",
      "[115 rows x 2 columns],      Fedu  G3\n",
      "4       3  10\n",
      "5       3  15\n",
      "13      3  11\n",
      "17      3  10\n",
      "19      3  10\n",
      "..    ...  ..\n",
      "365     3  10\n",
      "368     3  10\n",
      "378     3  15\n",
      "382     3  10\n",
      "387     3   0\n",
      "\n",
      "[100 rows x 2 columns],      Fedu  G3\n",
      "76      0  10\n",
      "171     0  16]\n",
      "[        Mjob  G3\n",
      "0    at_home   6\n",
      "1    at_home   6\n",
      "2    at_home  10\n",
      "39   at_home  13\n",
      "79   at_home   5\n",
      "86   at_home   6\n",
      "95   at_home  10\n",
      "112  at_home  13\n",
      "120  at_home  15\n",
      "127  at_home   9\n",
      "131  at_home   0\n",
      "134  at_home   0\n",
      "136  at_home   0\n",
      "143  at_home  13\n",
      "147  at_home  11\n",
      "151  at_home  14\n",
      "155  at_home   8\n",
      "157  at_home  10\n",
      "158  at_home  15\n",
      "160  at_home   0\n",
      "163  at_home  10\n",
      "173  at_home   0\n",
      "189  at_home  10\n",
      "191  at_home   9\n",
      "192  at_home   8\n",
      "205  at_home   9\n",
      "208  at_home  10\n",
      "218  at_home   8\n",
      "219  at_home  10\n",
      "220  at_home   6\n",
      "221  at_home   0\n",
      "228  at_home   9\n",
      "235  at_home  10\n",
      "238  at_home  11\n",
      "251  at_home  10\n",
      "264  at_home   0\n",
      "273  at_home  14\n",
      "274  at_home  10\n",
      "282  at_home  12\n",
      "286  at_home  19\n",
      "309  at_home  10\n",
      "311  at_home  13\n",
      "314  at_home  13\n",
      "318  at_home  10\n",
      "324  at_home  15\n",
      "331  at_home  14\n",
      "334  at_home   0\n",
      "343  at_home   0\n",
      "344  at_home  10\n",
      "352  at_home   8\n",
      "359  at_home  16\n",
      "360  at_home  13\n",
      "361  at_home  12\n",
      "363  at_home  15\n",
      "365  at_home  10\n",
      "368  at_home  10\n",
      "371  at_home  12\n",
      "379  at_home  10\n",
      "385  at_home  10,        Mjob  G3\n",
      "3    health  15\n",
      "12   health  14\n",
      "15   health  14\n",
      "19   health  10\n",
      "21   health  15\n",
      "27   health  15\n",
      "30   health  12\n",
      "47   health  20\n",
      "51   health  13\n",
      "52   health  10\n",
      "60   health  11\n",
      "68   health   8\n",
      "109  health  16\n",
      "114  health   9\n",
      "123  health  13\n",
      "146  health   0\n",
      "167  health  16\n",
      "169  health  14\n",
      "188  health   9\n",
      "200  health  16\n",
      "230  health  14\n",
      "233  health  13\n",
      "240  health  12\n",
      "255  health   8\n",
      "268  health  10\n",
      "278  health   8\n",
      "291  health  15\n",
      "295  health  11\n",
      "296  health   0\n",
      "300  health  11\n",
      "303  health  18\n",
      "348  health  15\n",
      "351  health  13\n",
      "376  health  15,       Mjob  G3\n",
      "4    other  10\n",
      "6    other  11\n",
      "7    other   6\n",
      "9    other  15\n",
      "14   other  16\n",
      "..     ...  ..\n",
      "383  other   0\n",
      "384  other   5\n",
      "389  other   0\n",
      "392  other   7\n",
      "394  other   9\n",
      "\n",
      "[141 rows x 2 columns],          Mjob  G3\n",
      "5    services  15\n",
      "8    services  19\n",
      "11   services  12\n",
      "16   services  14\n",
      "18   services   5\n",
      "..        ...  ..\n",
      "370  services   9\n",
      "387  services   0\n",
      "390  services   9\n",
      "391  services  16\n",
      "393  services  10\n",
      "\n",
      "[103 rows x 2 columns],         Mjob  G3\n",
      "10   teacher   9\n",
      "13   teacher  11\n",
      "20   teacher  15\n",
      "22   teacher  16\n",
      "29   teacher  11\n",
      "32   teacher  16\n",
      "36   teacher  18\n",
      "41   teacher  12\n",
      "48   teacher  14\n",
      "57   teacher  15\n",
      "63   teacher   9\n",
      "65   teacher  15\n",
      "75   teacher  10\n",
      "76   teacher  10\n",
      "89   teacher   7\n",
      "93   teacher  10\n",
      "110  teacher  19\n",
      "113  teacher  19\n",
      "115  teacher  16\n",
      "129  teacher  18\n",
      "139  teacher  15\n",
      "140  teacher   0\n",
      "142  teacher  11\n",
      "148  teacher   0\n",
      "172  teacher  10\n",
      "175  teacher   9\n",
      "178  teacher   9\n",
      "180  teacher   8\n",
      "197  teacher  10\n",
      "199  teacher  10\n",
      "207  teacher  13\n",
      "209  teacher   7\n",
      "224  teacher  14\n",
      "232  teacher   9\n",
      "241  teacher  12\n",
      "242  teacher   0\n",
      "256  teacher  13\n",
      "261  teacher   8\n",
      "267  teacher  11\n",
      "277  teacher   9\n",
      "279  teacher  10\n",
      "281  teacher  10\n",
      "289  teacher  15\n",
      "290  teacher  11\n",
      "299  teacher  16\n",
      "307  teacher   8\n",
      "319  teacher  11\n",
      "328  teacher   9\n",
      "329  teacher  14\n",
      "341  teacher   0\n",
      "346  teacher  16\n",
      "347  teacher   9\n",
      "356  teacher  13\n",
      "366  teacher  13\n",
      "377  teacher  10\n",
      "380  teacher  14\n",
      "386  teacher   6\n",
      "388  teacher   8]\n",
      "[        Fjob  G3\n",
      "0    teacher   6\n",
      "7    teacher   6\n",
      "29   teacher  11\n",
      "37   teacher  15\n",
      "42   teacher  18\n",
      "49   teacher   7\n",
      "60   teacher  11\n",
      "101  teacher  17\n",
      "110  teacher  19\n",
      "115  teacher  16\n",
      "116  teacher  14\n",
      "129  teacher  18\n",
      "130  teacher   0\n",
      "134  teacher   0\n",
      "139  teacher  15\n",
      "148  teacher   0\n",
      "154  teacher  12\n",
      "196  teacher  16\n",
      "198  teacher  18\n",
      "199  teacher  10\n",
      "222  teacher  17\n",
      "232  teacher   9\n",
      "287  teacher  12\n",
      "289  teacher  15\n",
      "299  teacher  16\n",
      "301  teacher  10\n",
      "329  teacher  14\n",
      "369  teacher  11\n",
      "380  teacher  14,       Fjob  G3\n",
      "1    other   6\n",
      "2    other  10\n",
      "4    other  10\n",
      "5    other  15\n",
      "6    other  11\n",
      "..     ...  ..\n",
      "385  other  10\n",
      "387  other   0\n",
      "389  other   0\n",
      "392  other   7\n",
      "393  other  10\n",
      "\n",
      "[217 rows x 2 columns],          Fjob  G3\n",
      "3    services  15\n",
      "12   services  14\n",
      "16   services  14\n",
      "18   services   5\n",
      "25   services   8\n",
      "..        ...  ..\n",
      "382  services  10\n",
      "383  services   0\n",
      "388  services   8\n",
      "390  services   9\n",
      "391  services  16\n",
      "\n",
      "[111 rows x 2 columns],        Fjob  G3\n",
      "10   health   9\n",
      "21   health  15\n",
      "24   health   8\n",
      "38   health  11\n",
      "52   health  10\n",
      "57   health  15\n",
      "63   health   9\n",
      "89   health   7\n",
      "94   health  14\n",
      "105  health  11\n",
      "109  health  16\n",
      "122  health  13\n",
      "169  health  14\n",
      "217  health   8\n",
      "274  health  10\n",
      "278  health   8\n",
      "303  health  18\n",
      "314  health  13,         Fjob  G3\n",
      "32   at_home  16\n",
      "44   at_home   9\n",
      "58   at_home   9\n",
      "99   at_home   8\n",
      "135  at_home   0\n",
      "143  at_home  13\n",
      "153  at_home   0\n",
      "219  at_home  10\n",
      "257  at_home  11\n",
      "273  at_home  14\n",
      "286  at_home  19\n",
      "292  at_home  13\n",
      "305  at_home  12\n",
      "324  at_home  15\n",
      "336  at_home  13\n",
      "343  at_home   0\n",
      "363  at_home  15\n",
      "372  at_home  11\n",
      "386  at_home   6\n",
      "394  at_home   9]\n",
      "[     reason  G3\n",
      "0    course   6\n",
      "1    course   6\n",
      "12   course  14\n",
      "13   course  11\n",
      "18   course   5\n",
      "..      ...  ..\n",
      "390  course   9\n",
      "391  course  16\n",
      "392  course   7\n",
      "393  course  10\n",
      "394  course   9\n",
      "\n",
      "[145 rows x 2 columns],     reason  G3\n",
      "2    other  10\n",
      "21   other  15\n",
      "27   other  15\n",
      "35   other   6\n",
      "49   other   7\n",
      "51   other  13\n",
      "52   other  10\n",
      "54   other  13\n",
      "55   other  10\n",
      "60   other  11\n",
      "100  other   5\n",
      "101  other  17\n",
      "109  other  16\n",
      "178  other   9\n",
      "185  other  11\n",
      "186  other  11\n",
      "192  other   8\n",
      "207  other  13\n",
      "214  other  10\n",
      "222  other  17\n",
      "247  other   8\n",
      "249  other  15\n",
      "252  other   8\n",
      "266  other  10\n",
      "286  other  19\n",
      "311  other  13\n",
      "345  other  14\n",
      "356  other  13\n",
      "361  other  12\n",
      "362  other  10\n",
      "366  other  13\n",
      "369  other  11\n",
      "371  other  12\n",
      "381  other   7\n",
      "383  other   0\n",
      "385  other  10,     reason  G3\n",
      "3     home  15\n",
      "4     home  10\n",
      "6     home  11\n",
      "7     home   6\n",
      "8     home  19\n",
      "..     ...  ..\n",
      "375   home  10\n",
      "378   home  15\n",
      "380   home  14\n",
      "382   home  10\n",
      "384   home   5\n",
      "\n",
      "[109 rows x 2 columns],          reason  G3\n",
      "5    reputation  15\n",
      "10   reputation   9\n",
      "11   reputation  12\n",
      "16   reputation  14\n",
      "17   reputation  10\n",
      "..          ...  ..\n",
      "357  reputation  11\n",
      "367  reputation   0\n",
      "374  reputation  19\n",
      "379  reputation  10\n",
      "386  reputation   6\n",
      "\n",
      "[105 rows x 2 columns]]\n",
      "{'variable': 'Medu', 'statistic': 20.965272048704946, 'pvalue': 8.49017278323326e-06}\n",
      "{'variable': 'Fedu', 'statistic': 10.087338049374276, 'pvalue': 0.0017630928393755144}\n",
      "{'variable': 'Mjob', 'statistic': 9.313348035987374, 'pvalue': 0.002981454150613827}\n",
      "{'variable': 'Fjob', 'statistic': 3.741017809408278, 'pvalue': 0.05424841968457241}\n",
      "{'variable': 'reason', 'statistic': 2.3843787145700515, 'pvalue': 0.1243196822055902}\n",
      "{'variable': 'age', 'statistic': 1.1027568354139103, 'pvalue': 0.2950855248030284}\n"
     ]
    }
   ],
   "source": [
    "#sort variables by ascending p-values (lower the p-values, higher the significance)\n",
    "anova_res_lst = calculate_anova_results(anova_lst, data_mat)\n",
    "sorted_results = sorted(anova_res_lst, key=lambda x: x['pvalue'])\n",
    "for item in sorted_results:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_significant_variables(anova_res_lst: list) -> None:\n",
    "    \"\"\"\n",
    "    Print the variables that have a significant p-value (< 0.05) from a list of ANOVA results.\n",
    "\n",
    "    Args:\n",
    "        anova_res_lst (list): A list of dictionaries containing ANOVA results for different variables.\n",
    "            Each dictionary contains the variable name and its corresponding p-value.\n",
    "\n",
    "    Returns:\n",
    "        None: This function doesn't return anything, it just prints the significant variables.\n",
    "\n",
    "    \"\"\"\n",
    "    # Sort the list of ANOVA results by p-value in ascending order\n",
    "    sorted_results = sorted(anova_res_lst, key=lambda x: float(x.get('pvalue')))\n",
    "    \n",
    "    # Iterate through each dictionary in the sorted list of ANOVA results\n",
    "    for result in sorted_results:\n",
    "        # Get the variable name and p-value from the current dictionary\n",
    "        variable = result.get('variable')\n",
    "        pvalue = float(result.get('pvalue'))\n",
    "        \n",
    "        # Check if the p-value is less than 0.05 (i.e. significant)\n",
    "        if pvalue < 0.05:\n",
    "            # If significant, print the variable name\n",
    "            print(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medu\n",
      "Fedu\n",
      "Mjob\n"
     ]
    }
   ],
   "source": [
    "print_significant_variables(anova_res_lst)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With one-way ANOVA, we can conclude that these features (Mother's Education, Father's Education, Mother's Job, Address and Sex) show differences in grades among the students, which might indicate that some background factors have an effect on students' grades. This also supports our initial hypothesis that parent's education play a big part in students' grades.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Student t-Test Analysis of Student's grade \n",
    "\n",
    "We will use student t-test to determine if providing extra educational support does improves students' grades\n",
    "\n",
    "- Null Hypothesis: There is no significant difference in the mean students' grades between the groups that received extra educational support and the group that did not receive extra educational support.\n",
    "- Alternate Hypothesis: There is a significant difference in the mean students' grades between the groups that received extra educational support and the group that did not receive extra educational support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind\n",
    "\n",
    "def student_t_test(feat1, grade ,df, alpha):\n",
    "    \n",
    "    group1 = df[df[feat1]== 'yes'][grade]\n",
    "    group2 = df[df[feat1]== 'no'][grade]\n",
    "\n",
    "    stat, p = ttest_ind(group1, group2)\n",
    "    \n",
    "    if p < alpha:\n",
    "        print(f\"Test Statistic: {stat}, p_value: {p} < alpha: {alpha}, {feat1} does improve grades\")\n",
    "    else:\n",
    "        print(f\"Test Statistic: {stat}, p_value: {p} > alpha: {alpha}, {feat1} does not improve grades\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: -1.6468658378374499, p_value: 0.10038496363910418 > alpha: 0.05, schoolsup does not improve grades\n"
     ]
    }
   ],
   "source": [
    "student_t_test('schoolsup', 'G3', data_mat, 0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With student t-test, we can conclude that providing extra educational support does not improve grades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Statistic: -0.7768559575314726, p_value: 0.43771108589489893 > alpha: 0.05, famsup does not improve grades\n"
     ]
    }
   ],
   "source": [
    "student_t_test('famsup', 'G3', data_mat, 0.05)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly, with student t-test, we an conclude providing family education support does not improve grades"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
